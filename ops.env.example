# Staging/ops tuning for sensor polling & event bus
SYSGROW_EVENTBUS_WORKERS=8
SYSGROW_EVENTBUS_QUEUE_SIZE=2048
SYSGROW_MQTT_RATE_LIMIT_SEC=2
SYSGROW_MQTT_COALESCE_FLUSH_SEC=2
SYSGROW_SENSOR_BACKOFF_BASE_SEC=2
SYSGROW_SENSOR_BACKOFF_MAX_SEC=60
SYSGROW_POLLING_HEARTBEAT_SEC=10

# --------------------------------------------------------------------------
# LLM Configuration  (recommendation engine & decision advisor)
# --------------------------------------------------------------------------
# Provider: "none" (disabled), "openai", "anthropic", "local"
LLM_PROVIDER=none

# --- Cloud API providers (OpenAI / Anthropic) ---
# LLM_API_KEY=sk-...              # OpenAI key   -or-  Anthropic key
# LLM_MODEL=gpt-4o-mini           # OpenAI: gpt-4o-mini | gpt-4o | ...
#                                  # Anthropic: claude-3-5-haiku-latest | claude-sonnet-4-20250514 | ...
# LLM_BASE_URL=                    # Optional: custom endpoint (Azure OpenAI, proxy)
# LLM_TIMEOUT=30                   # Request timeout in seconds

# --- Local model (EXAONE 4.0 1.2B / any HuggingFace causal-LM) ---
# LLM_LOCAL_MODEL_PATH=LGAI-EXAONE/EXAONE-4.0-1.2B-Instruct
# LLM_LOCAL_DEVICE=auto            # "cpu" | "cuda" | "mps" | "auto"
# LLM_LOCAL_QUANTIZE=false         # 4-bit quantisation (needs bitsandbytes)
# LLM_LOCAL_TORCH_DTYPE=float16    # float16 | bfloat16 | float32

# --- Generation defaults ---
# LLM_MAX_TOKENS=512
# LLM_TEMPERATURE=0.3
